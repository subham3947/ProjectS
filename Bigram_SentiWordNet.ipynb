{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\nltk\\tag\\stanford.py:149: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordPOSTagger, self).__init__(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "from nltk import word_tokenize,sent_tokenize,pos_tag\n",
    "from nltk.tag import StanfordPOSTagger\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "java_path = \"C:/Program Files/Java/jdk1.8.0_144/bin/java.exe\"\n",
    "os.environ['JAVAHOME'] = java_path\n",
    "model='stanford-postagger-2018-02-27/models/english-left3words-distsim.tagger'\n",
    "jar='stanford-postagger-2018-02-27/stanford-postagger-3.9.1.jar'\n",
    "st=StanfordPOSTagger(model,jar,encoding='utf-8')\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "punctuations = '''!()-[]{};—:'\"\\,<>./’?@#$%^&*_~“”'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=['i','me','my','myself','we','our','ours','ourselves','you','your','yours','yourself','yourselves','he','him','his','himself'\n",
    ",'she','her','hers','herself','it','its','itself','they','them','their','theirs','themselves','what','which','who','whom',\n",
    " 'this','that','these','those','am','is','are','was','were','be','been','being','have','has','had','having','do','does','did','doing','a',\n",
    " 'an','the','and','but','if','or','because','as','until','while','of','at','by','for','with','about','between','into','through','during',\n",
    " 'before','after','to','from','again','then','once','here','there','when','where','why','how','all','any','both','each',\n",
    " 'than','should','d','ll','m','o','re','ve','y','ma']\n",
    "stopwords=stopwords+list(punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg= {\"aint\", \"arent\", \"cannot\", \"cant\", \"couldnt\", \"darent\", \"didnt\", \"doesnt\",\n",
    " \"ain't\", \"aren't\", \"can't\", \"couldn't\", \"daren't\", \"didn't\", \"doesn't\",\n",
    " \"dont\", \"hadnt\", \"hasnt\", \"havent\", \"isnt\", \"mightnt\", \"mustnt\", \"neither\",\n",
    " \"don't\", \"hadn't\", \"hasn't\", \"haven't\", \"isn't\", \"mightn't\", \"mustn't\",\n",
    " \"neednt\", \"needn't\", \"never\",\"no\", \"none\", \"nope\", \"nor\", \"not\", \"nothing\", \"nowhere\",\n",
    " \"oughtnt\", \"shant\", \"shouldnt\", \"uhuh\", \"wasnt\", \"werent\",\n",
    " \"oughtn't\", \"shan't\", \"shouldn't\", \"uh-uh\", \"wasn't\", \"weren't\",\n",
    " \"without\", \"wont\", \"wouldnt\", \"won't\", \"wouldn't\", \"rarely\", \"seldom\",\"minimise\", \"despite\",\"unfulfilled\",\"undue\",\"anti\",\"against\",\"without\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost={\"absolutely\":0.5, \"amazingly\":0.125, \"awfully\":0.25, \"completely\":0.25, \"considerably\":0.125,\n",
    " \"decidedly\":0.25 , \"deeply\":0.25 , \"enormously\":0.25 ,\n",
    " \"entirely\":0.5 , \"especially\":0.25 , \"exceptionally\":0.25, \"extremely\":0.625 ,\"fabulously\":0.25   , \"fully\":0.375  ,\n",
    " \"greatly\":0.125 , \"highly\":0.5   ,\"huge\":0.25, \"hugely\":0.25   , \"incredibly\":0.25   ,\n",
    " \"intensely\":0.25   , \"majorly\":0.625  ,\"particularly\":0.125 ,\"really\":0.375 ,\"substantially\":0.125   ,\n",
    " \"thoroughly\":0.625   , \"totally\":0.5  ,\"unbelievably\":0.25   , \"utterly\":0.5   ,\n",
    " \"very\":0.25  ,\"tremendously\":-0.25 ,  \"barely\":-0.375   ,\"badly\":-0.125 ,\"hardly\":-0.25,\"unusually\":-0.5   , \n",
    " \"less\":-0.5   , \"little\":-0.375   , \"marginally\":-0.125   , \"partly\":-0.125   ,\n",
    " \"scarcely\":-0.25   , \"slightly\":-0.25   , \"somewhat\":-0.125, \"shoddy\":-0.625, \"poorly\":-0.75}\n",
    "pos_boost=[\"absolutely\", \"amazingly\", \"awfully\", \"completely\", \"considerably\",\n",
    " \"decidedly\",\"deeply\",\"enormously\",\"entirely\",\"especially\",\"exceptionally\",\"extremely\",\"fabulously\",\"fully\",\n",
    " \"greatly\",\"highly\",\"huge\",\"hugely\", \"incredibly\",\"intensely\",\"majorly\",\"particularly\",\"really\",\"substantially\",\"thoroughly\",\"totally\",\"unbelievably\", \"utterly\",\"very\"]\n",
    "neg_boost=[\"tremendously\", \"barely\",\"badly\",\"hardly\",\"unusually\", \"less\", \"little\", \"marginally\", \"partly\",\n",
    " \"scarcely\", \"slightly\",\"somewhat\", \"shoddy\", \"poorly\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tag(tag):\n",
    "    \n",
    "    if tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    elif tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns=open('sent_nouns.txt','r',encoding='utf-8')\n",
    "nouns=nouns.read()\n",
    "nouns=nouns.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = '''!@'#-+=_'''\n",
    "def clean_tweet(t):\n",
    "    for c in punctuations:\n",
    "             t= t.replace(c,\" \")\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_booster(booster,word,pos2):\n",
    "    sec_score=get_sentiment(word,pos2)\n",
    "    if sec_score>0.0:\n",
    "        return(boost[booster]+sec_score)\n",
    "    if sec_score<0.0:\n",
    "        return(sec_score-boost[booster])\n",
    "    else:\n",
    "        return(boost[booster])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_booster(booster,word,pos2):\n",
    "    sec_score=get_sentiment(word,pos2)\n",
    "    if sec_score>0.0:\n",
    "        return(sec_score+boost[booster])\n",
    "    if sec_score<0.0:\n",
    "        return(sec_score+boost[booster])\n",
    "    else:\n",
    "        return(boost[booster])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(word,wn_tag):\n",
    "    synsets = wn.synsets(word, pos=wn_tag)\n",
    "    if not synsets:\n",
    "        lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
    "        synsets = wn.synsets(lemma, pos=wn_tag)\n",
    "    synset = synsets[0]\n",
    "    swn_synset = swn.senti_synset(synset.name())\n",
    "    print(word,synset,swn_synset.pos_score(),swn_synset.neg_score())\n",
    "    return(swn_synset.pos_score() - swn_synset.neg_score())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet1='''The marginalization of the Tax Cheats which was expected post #GST will now happen in right earnest as #Ewaybill rolls out. Real benefits to most organized sector companies will be seen in FY2019'''\n",
    "tweet2='''From Failed #Demonetisation to Shoddy Implementation of #GST to poorly performing #Economy to unfulfilled Promise of reduction in fuel prices to not keeping the promises of providing 2 crores jobs, BJP has wrecked a nation & has broken people’s faith '''\n",
    "tweet3='''There is nothing wrong with #GST implementation but the fact is we are all losers. Injected to us by @INCIndia  Even God cannot change'''\n",
    "tweet4='''So, Indian businesses are mad against GST cause now they have to pay tax and earlier they weren't?'''\n",
    "tweet5='''#GST in india is total failure,it like nightmare for tax payers Indians..in my view it could be rolled out after #2019LSPolls after corrections ~ Dr Subramanian @Swamy39 Speaking at 14th Annual 🇮🇳India Business Conference on ‘Indian Growth @Columbia_Biz '''\n",
    "tweet6='''U know u r abt to witness #GST_Mess when a common citizen is forced to pay 28% #GST on BANANAS. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=word_tokenize(clean_tweet(tweet6.lower()))\n",
    "bigrams=nltk.ngrams(A,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-5ac34a1ad379>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mi\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m#b_tag=pos_tag(b)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mb_tag\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;31m#print(b_tag)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0msecond_gram\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb_tag\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\nltk\\tag\\stanford.py\u001b[0m in \u001b[0;36mtag\u001b[1;34m(self, tokens)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;31m# This function should return list of tuple rather than list of list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag_sents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtag_sents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\nltk\\tag\\stanford.py\u001b[0m in \u001b[0;36mtag_sents\u001b[1;34m(self, sentences)\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;31m# Run the tagger and get the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         stanpos_output, _stderr = java(cmd, classpath=self._stanford_jar,\n\u001b[1;32m--> 107\u001b[1;33m                                        stdout=PIPE, stderr=PIPE)\n\u001b[0m\u001b[0;32m    108\u001b[0m         \u001b[0mstanpos_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstanpos_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\nltk\\__init__.py\u001b[0m in \u001b[0;36mjava\u001b[1;34m(cmd, classpath, stdin, stdout, stderr, blocking)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstdin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mblocking\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;31m# Check the return code.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36-32\\lib\\subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[1;34m(self, input, timeout)\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 843\u001b[1;33m                 \u001b[0mstdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    844\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_communication_started\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36-32\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[1;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[0;32m   1090\u001b[0m             \u001b[1;31m# calls communicate again.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1092\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_remaining_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1093\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1094\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutExpired\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36-32\\lib\\threading.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m             \u001b[1;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36-32\\lib\\threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1070\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# already determined that the C code is done\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1071\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1072\u001b[1;33m         \u001b[1;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i=0\n",
    "not_found=set()\n",
    "score=0.0\n",
    "for b in bigrams:\n",
    "    i+=1\n",
    "    #b_tag=pos_tag(b)\n",
    "    b_tag=st.tag(b)\n",
    "    #print(b_tag)\n",
    "    second_gram=b_tag[1]\n",
    "    first_gram=b_tag[0]\n",
    "    if second_gram[0] in nouns or second_gram[1].startswith('J') or second_gram[1].startswith('RBR') or second_gram[1].startswith('RBS') or second_gram[1].startswith('VBG') or second_gram[1].startswith('VBN') or second_gram[1].startswith('VBD'):\n",
    "    #if second_gram[0] in nouns or second_gram[1].startswith('J') or second_gram[1].startswith('RBR') or second_gram[1].startswith('RBS') or second_gram[1].startswith('VB'):\n",
    "        pos2=convert_tag(second_gram[1])\n",
    "        pos1=convert_tag(first_gram[1])\n",
    "        \n",
    "        if first_gram[0] in boost:\n",
    "            if first_gram[0] in pos_boost:\n",
    "                score=positive_booster(first_gram[0],second_gram[0],pos2)\n",
    "                print('Pos-Boost:',b_tag,score)\n",
    "            if first_gram[0] in neg_boost:\n",
    "                score=negative_booster(first_gram[0],second_gram[0],pos2)\n",
    "                print('Neg-Boost:',b_tag,score)\n",
    "            \n",
    "   \n",
    "        if first_gram[0] in neg:\n",
    "                sec_score=get_sentiment(second_gram[0],pos2)\n",
    "                print(second_gram[0],sec_score)\n",
    "                if sec_score ==0.0 or sec_score==None:\n",
    "                    score+=(get_sentiment(first_gram[0],pos1)+sec_score)\n",
    "                else:\n",
    "                    score+=-(sec_score)\n",
    "                print('Neg:',b_tag,score)\n",
    "            \n",
    "        elif first_gram[0] not in neg and first_gram[0] not in boost:\n",
    "            try:\n",
    "                first_score=get_sentiment(first_gram[0],pos1)\n",
    "                score+=first_score+get_sentiment(second_gram[0],pos2)\n",
    "                print('Normal:',b_tag,score)\n",
    "            except:\n",
    "                print(\"Not Found:\",second_gram[0])\n",
    "                not_found.add(second_gram[0])\n",
    "    \n",
    "print(score)\n",
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(bigrams):\n",
    "    score=0.0\n",
    "    for b in bigrams:\n",
    "        b_tag=st.tag(b)\n",
    "        #b_tag=pos_tag(b)\n",
    "        #print(b_tag)\n",
    "        second_gram=b_tag[1]\n",
    "        first_gram=b_tag[0]\n",
    "        if second_gram[0] in nouns or second_gram[1].startswith('J') or second_gram[1].startswith('RBR') or second_gram[1].startswith('RBS') or second_gram[1].startswith('VBG') or second_gram[1].startswith('VBN') or second_gram[1].startswith('VBD'):\n",
    "            pos2=convert_tag(second_gram[1])\n",
    "            pos1=convert_tag(first_gram[1])\n",
    "        \n",
    "            if first_gram[0] in boost:\n",
    "                if first_gram[0] in pos_boost:\n",
    "                    score=positive_booster(first_gram[0],second_gram[0],pos2)\n",
    "                    print('Pos-Boost:',b_tag,score)\n",
    "                if first_gram[0] in neg_boost:\n",
    "                    score=negative_booster(first_gram[0],second_gram[0],pos2)\n",
    "                    print('Neg-Boost:',b_tag,score)\n",
    "            \n",
    "   \n",
    "            if first_gram[0] in neg:\n",
    "                x=0.0\n",
    "                sec_score=get_sentiment(second_gram[0],pos2)\n",
    "                print(second_gram[0],sec_score)\n",
    "                if sec_score ==0.0 or sec_score==None:\n",
    "                    try:\n",
    "                        x=get_sentiment(first_gram[0],pos1)\n",
    "                        score+=(x+sec_score)\n",
    "                    except:\n",
    "                        print(x)\n",
    "                else:\n",
    "                    score+=-(sec_score)\n",
    "                #print('Neg:',b_tag,score)\n",
    "            \n",
    "            elif first_gram[0] not in neg and first_gram[0] not in boost:\n",
    "                try:\n",
    "                    first_score=get_sentiment(first_gram[0],pos1)\n",
    "                    score+=first_score+get_sentiment(second_gram[0],pos2)\n",
    "                    #print('Normal:',b_tag,score)\n",
    "                except:\n",
    "                    print(\"Not Found:\",second_gram[0])\n",
    "                    #not_found.add(second_gram[0])\n",
    "    return ((score))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be Synset('be.v.01') 0.25 0.125\n",
      "smoother Synset('smooth.a.01') 0.25 0.0\n",
      "Not Found: expected\n",
      "go Synset('travel.v.01') 0.0 0.0\n",
      "more Synset('more.r.01') 0.0 0.0\n",
      "y2k Synset('y2k.n.01') 0.0 0.0\n",
      "hoax Synset('fraud.n.03') 0.0 0.125\n",
      "Not Found: pain\n",
      "Not Found: indian\n",
      "1\n",
      "2\n",
      "after Synset('after.s.01') 0.0 0.0\n",
      "paying Synset('pay.v.01') 0.0 0.0\n",
      "still Synset('still.r.01') 0.0 0.125\n",
      "paying Synset('pay.v.01') 0.0 0.0\n",
      "paying Synset('pay.v.01') 0.0 0.0\n",
      "less Synset('less.a.01') 0.0 0.5\n",
      "Not Found: usual\n",
      "i Synset('iodine.n.01') 0.0 0.0\n",
      "used Synset('use.v.01') 0.0 0.0\n",
      "ache Synset('ache.n.01') 0.25 0.5\n",
      "din Synset('blare.n.01') 0.0 0.25\n",
      "Not Found: promised\n",
      "3\n",
      "is Synset('be.v.01') 0.25 0.125\n",
      "capable Synset('capable.a.01') 0.125 0.0\n",
      "Not Found: handling\n",
      "at Synset('astatine.n.01') 0.0 0.0\n",
      "same Synset('same.a.01') 0.0 0.0\n",
      "4\n",
      "an Synset('associate_in_nursing.n.01') 0.0 0.125\n",
      "historic Synset('historic.s.01') 0.125 0.125\n",
      "Not Found: economic\n",
      "economic Synset('economic.a.01') 0.0 0.0\n",
      "reforms Synset('reform.n.01') 0.125 0.0\n",
      "5\n",
      "doubt Synset('doubt.n.01') 0.125 0.0\n",
      "doubt 0.125\n",
      "will Synset('volition.n.01') 0.125 0.0\n",
      "boost Synset('hike.v.01') 0.0 0.0\n",
      "6\n",
      "has Synset('have.v.01') 0.25 0.0\n",
      "created Synset('make.v.03') 0.0 0.0\n",
      "created Synset('make.v.03') 0.0 0.0\n",
      "emergency Synset('emergency.n.01') 0.125 0.625\n",
      "7\n",
      "ensure Synset('guarantee.v.02') 0.0 0.0\n",
      "greater Synset('greater.a.01') 0.5 0.25\n",
      "Not Found: more\n",
      "compliance Synset('conformity.n.02') 0.625 0.0\n",
      "more Synset('more.r.01') 0.0 0.0\n",
      "8\n",
      "is Synset('be.v.01') 0.25 0.125\n",
      "good Synset('good.a.01') 0.75 0.0\n",
      "is Synset('be.v.01') 0.25 0.125\n",
      "simple Synset('simple.a.01') 0.125 0.375\n",
      "it Synset('information_technology.n.01') 0.0 0.0\n",
      "benefits Synset('profit.v.01') 0.375 0.0\n",
      "9\n",
      "is Synset('be.v.01') 0.25 0.125\n",
      "putting Synset('put.v.01') 0.0 0.0\n",
      "10\n",
      "affected Synset('affect.v.01') 0.125 0.0\n",
      "Neg-Boost: [('badly', 'RB'), ('affected', 'VBN')] 0.0\n",
      "11\n",
      "see Synset('see.v.01') 0.0 0.0\n",
      "accelerated Synset('accelerate.v.01') 0.0 0.0\n",
      "accelerated Synset('accelerate.v.01') 0.0 0.0\n",
      "growth Synset('growth.n.01') 0.0 0.0\n",
      "12\n",
      "Not Found: new\n",
      "13\n",
      "massive Synset('massive.s.01') 0.0 0.0\n",
      "protests Synset('protest.n.01') 0.0 0.0\n",
      "are Synset('be.v.01') 0.25 0.125\n",
      "continuing Synset('continue.v.01') 0.0 0.0\n",
      "are Synset('be.v.01') 0.25 0.125\n",
      "demanding Synset('demand.v.01') 0.0 0.25\n",
      "14\n",
      "shade Synset('shade.n.01') 0.0 0.0\n",
      "lower Synset('low.a.01') 0.0 0.25\n",
      "Not Found: previous\n",
      "previous Synset('previous.s.01') 0.0 0.0\n",
      "indirect Synset('indirect.s.01') 0.0 0.0\n",
      "15\n",
      "simmering Synset('simmer.v.01') 0.0 0.375\n",
      "discontent Synset('discontentment.n.01') 0.125 0.0\n",
      "Not Found: dominated\n",
      "16\n",
      "are Synset('be.v.01') 0.25 0.125\n",
      "drowned Synset('submerge.v.02') 0.0 0.0\n",
      "Not Found: din\n",
      "on Synset('on.a.01') 0.0 0.0\n",
      "showier Synset('flamboyant.s.01') 0.5 0.0\n",
      "showier Synset('flamboyant.s.01') 0.5 0.0\n",
      "issues Synset('issue.n.01') 0.125 0.0\n",
      "17\n",
      "handsets Synset('handset.n.01') 0.0 0.0\n",
      "sold Synset('sell.v.01') 0.0 0.0\n",
      "sold Synset('sell.v.01') 0.0 0.0\n",
      "Not Found: offline\n",
      "is Synset('be.v.01') 0.25 0.125\n",
      "18th Synset('eighteenth.s.01') 0.0 0.0\n",
      "all Synset('all.a.01') 0.0 0.0\n",
      "going Synset('travel.v.01') 0.0 0.0\n",
      "going Synset('travel.v.01') 0.0 0.0\n",
      "cheap Synset('cheap.a.01') 0.0 0.25\n",
      "18\n",
      "an Synset('associate_in_nursing.n.01') 0.0 0.125\n",
      "insensitive Synset('insensitive.a.01') 0.0 0.625\n",
      "19\n",
      "Not Found: demonetization\n",
      "20\n",
      "a Synset('angstrom.n.01') 0.0 0.0\n",
      "gripping Synset('grip.v.01') 0.375 0.0\n",
      "is Synset('be.v.01') 0.25 0.125\n",
      "painful Synset('painful.a.01') 0.125 0.75\n",
      "Not Found: difficult\n",
      "21\n",
      "afford Synset('afford.v.01') 0.0 0.0\n",
      "afford 0.0\n",
      "not Synset('not.r.01') 0.0 0.625\n",
      "buy Synset('buy.v.01') 0.0 0.0\n",
      "sanitary Synset('sanitary.a.01') 0.625 0.25\n",
      "22\n",
      "good Synset('good.a.01') 0.75 0.0\n",
      "Pos-Boost: [('very', 'RB'), ('good', 'JJ')] 1.0\n",
      "a Synset('angstrom.n.01') 0.0 0.0\n",
      "few Synset('few.a.01') 0.0 0.0\n",
      "sectors Synset('sector.n.01') 0.0 0.0\n",
      "experiencing Synset('experience.v.01') 0.0 0.0\n",
      "experiencing Synset('experience.v.01') 0.0 0.0\n",
      "reduction Synset('decrease.n.04') 0.0 0.0\n",
      "past Synset('past.a.01') 0.0 0.25\n",
      "few Synset('few.a.01') 0.0 0.0\n",
      "23\n",
      "Not Found: central\n",
      "has Synset('have.v.01') 0.25 0.0\n",
      "been Synset('be.v.01') 0.25 0.125\n",
      "been Synset('be.v.01') 0.25 0.125\n",
      "remarkable Synset('remarkable.s.01') 0.25 0.25\n",
      "has Synset('have.v.01') 0.25 0.0\n",
      "unified Synset('unify.v.01') 0.0 0.0\n",
      "24\n",
      "Not Found: latest\n",
      "25\n",
      "Not Found: protest\n",
      "send Synset('send.v.01') 0.0 0.0\n",
      "sanitary Synset('sanitary.a.01') 0.625 0.25\n",
      "26\n",
      "are Synset('be.v.01') 0.25 0.125\n",
      "drowned Synset('submerge.v.02') 0.0 0.0\n",
      "Not Found: din\n",
      "on Synset('on.a.01') 0.0 0.0\n",
      "showier Synset('flamboyant.s.01') 0.5 0.0\n",
      "showier Synset('flamboyant.s.01') 0.5 0.0\n",
      "issues Synset('issue.n.01') 0.125 0.0\n",
      "27\n",
      "Not Found: central\n",
      "Not Found: gstsimplified\n",
      "Not Found: good\n",
      "Not Found: simple\n",
      "28\n",
      "keep Synset('keep.v.01') 0.0 0.0\n",
      "smiling Synset('smile.v.01') 0.0 0.0\n",
      "29\n",
      "well Synset('well.r.01') 0.375 0.0\n",
      "explained Synset('explain.v.01') 0.25 0.0\n",
      "explained Synset('explain.v.01') 0.25 0.0\n",
      "issue Synset('issue.n.01') 0.125 0.0\n",
      "on Synset('on.a.01') 0.0 0.0\n",
      "sanitary Synset('sanitary.a.01') 0.625 0.25\n",
      "making Synset('make.v.01') 0.0 0.0\n",
      "huge Synset('huge.s.01') 0.0 0.125\n",
      "30\n",
      "31\n",
      "holy Synset('holy.a.01') 0.0 0.0\n",
      "golden Synset('aureate.s.02') 0.0 0.0\n",
      "Not Found: liability\n",
      "32\n",
      "Not Found: advantages\n",
      "Not Found: disadvantages\n",
      "33\n",
      "Not Found: complexities\n",
      "Not Found: high\n",
      "killing Synset('kill.v.01') 0.0 0.5\n",
      "Pos-Boost: [('really', 'RB'), ('killing', 'VBG')] -0.875\n",
      "killing Synset('kill.v.01') 0.0 0.5\n",
      "small Synset('small.a.01') 0.0 0.375\n",
      "ultimately Synset('ultimately.r.01') 0.0 0.0\n",
      "benefitting Synset('profit.v.01') 0.375 0.0\n",
      "Not Found: big\n",
      "34\n",
      "consumers Synset('consumer.n.01') 0.0 0.0\n",
      "complain Synset('complain.v.01') 0.0 0.75\n",
      "retailers Synset('retailer.n.01') 0.0 0.0\n",
      "charging Synset('charge.v.01') 0.0 0.0\n",
      "officials Synset('official.n.01') 0.0 0.0\n",
      "working Synset('work.v.01') 0.0 0.0\n",
      "Not Found: issues\n",
      "35\n",
      "has Synset('have.v.01') 0.25 0.0\n",
      "failed Synset('fail.v.01') 0.0 0.125\n",
      "36\n",
      "had Synset('have.v.01') 0.25 0.0\n",
      "fruitful Synset('fruitful.a.01') 0.5 0.0\n",
      "fruitful Synset('fruitful.a.01') 0.5 0.0\n",
      "interactive Synset('synergistic.a.01') 0.0 0.0\n",
      "Not Found: included\n",
      "37\n",
      "officials Synset('official.n.01') 0.0 0.0\n",
      "attended Synset('attend.v.01') 0.0 0.0\n",
      "Not Found: addressed\n",
      "Not Found: concerns\n",
      "38\n",
      "39\n",
      "drive Synset('drive.n.01') 0.0 0.0\n",
      "growth Synset('growth.n.01') 0.0 0.0\n",
      "one Synset('one.n.01') 0.0 0.0\n",
      "important Synset('important.a.01') 0.875 0.0\n",
      "40\n",
      "post Synset('post.n.01') 0.0 0.0\n",
      "sanitary Synset('sanitary.a.01') 0.625 0.25\n",
      "41\n",
      "delhi Synset('delhi.n.01') 0.0 0.0\n",
      "high Synset('high.a.01') 0.125 0.25\n",
      "42\n",
      "Not Found: demonetisation\n",
      "index Synset('index.n.01') 0.0 0.0\n",
      "Not Found: low.industrial\n",
      "rate Synset('rate.n.01') 0.0 0.0\n",
      "low Synset('low.a.01') 0.0 0.25\n",
      "43\n",
      "traders Synset('trader.n.01') 0.0 0.0\n",
      "hit Synset('hit.v.01') 0.0 0.0\n",
      "in Synset('inch.n.01') 0.0 0.0\n",
      "protest Synset('protest.n.01') 0.0 0.0\n",
      "44\n",
      "s Synset('second.n.01') 0.0 0.0\n",
      "looking Synset('look.v.01') 0.0 0.0\n",
      "looking Synset('look.v.01') 0.0 0.0\n",
      "more Synset('more.r.01') 0.0 0.0\n",
      "Not Found: more\n",
      "45\n",
      "a Synset('angstrom.n.01') 0.0 0.0\n",
      "critical Synset('critical.a.01') 0.0 0.5\n",
      "critical Synset('critical.a.01') 0.0 0.5\n",
      "reform Synset('reform.n.01') 0.125 0.0\n",
      "drive Synset('drive.n.01') 0.0 0.0\n",
      "economic Synset('economic.a.01') 0.0 0.0\n",
      "economic Synset('economic.a.01') 0.0 0.0\n",
      "growth Synset('growth.n.01') 0.0 0.0\n",
      "46\n",
      "industry Synset('industry.n.01') 0.0 0.0\n",
      "strike Synset('strike.n.01') 0.0 0.125\n",
      "enters Synset('enter.v.01') 0.0 0.0\n",
      "third Synset('third.s.01') 0.0 0.0\n",
      "47\n",
      "going Synset('travel.v.01') 0.0 0.0\n",
      "going 0.0\n",
      "not Synset('not.r.01') 0.0 0.625\n",
      "Not Found: protest\n",
      "is Synset('be.v.01') 0.25 0.125\n",
      "meaningless Synset('meaningless.a.01') 0.125 0.375\n",
      "Not Found: useless\n",
      "ur Synset('ur.n.01') 0.0 0.0\n",
      "protest Synset('protest.n.01') 0.0 0.0\n",
      "48\n",
      "49\n",
      "Not Found: illegal\n",
      "stopped Synset('stop.v.01') 0.0 0.0\n",
      "Pos-Boost: [('completely', 'RB'), ('stopped', 'VBD')] 0.25\n",
      "50\n",
      "much Synset('much.r.01') 0.125 0.0\n",
      "complex Synset('complex.n.01') 0.0 0.0\n",
      "be Synset('be.v.01') 0.25 0.125\n",
      "understood Synset('understand.v.01') 0.375 0.0\n",
      "a Synset('angstrom.n.01') 0.0 0.0\n",
      "small Synset('small.a.01') 0.0 0.375\n",
      "51\n",
      "cess Synset('cerium.n.01') 0.0 0.0\n",
      "hike Synset('hike.n.01') 0.0 0.0\n",
      "is Synset('be.v.01') 0.25 0.125\n",
      "rude Synset('ill-mannered.s.01') 0.0 0.625\n",
      "who Synset('world_health_organization.n.01') 0.0 0.0\n",
      "bought Synset('buy.v.01') 0.0 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bought Synset('buy.v.01') 0.0 0.0\n",
      "myth Synset('myth.n.01') 0.0 0.0\n",
      "be Synset('be.v.01') 0.25 0.125\n",
      "predictable Synset('predictable.a.01') 0.0 0.0\n",
      "Not Found: stable\n",
      "52\n",
      "Not Found: hiking\n",
      "is Synset('be.v.01') 0.25 0.125\n",
      "good Synset('good.a.01') 0.75 0.0\n",
      "53\n",
      "indian Synset('indian.a.01') 0.0 0.0\n",
      "real Synset('real.a.01') 0.0 0.0\n",
      "is Synset('be.v.01') 0.25 0.125\n",
      "witnessing Synset('witness.v.01') 0.0 0.0\n",
      "witnessing Synset('witness.v.01') 0.0 0.0\n",
      "huge Synset('huge.s.01') 0.0 0.125\n",
      "is Synset('be.v.01') 0.25 0.125\n",
      "huge Synset('huge.s.01') 0.0 0.125\n",
      "Not Found: other\n",
      "54\n",
      "delhi Synset('delhi.n.01') 0.0 0.0\n",
      "high Synset('high.a.01') 0.125 0.25\n",
      "on Synset('on.a.01') 0.0 0.0\n",
      "plea Synset('supplication.n.02') 0.0 0.125\n",
      "on Synset('on.a.01') 0.0 0.0\n",
      "sanitary Synset('sanitary.a.01') 0.625 0.25\n",
      "55\n",
      "exchange Synset('exchange.n.01') 0.0 0.0\n",
      "old Synset('old.a.01') 0.375 0.0\n",
      "Not Found: added\n",
      "56\n",
      "will Synset('volition.n.01') 0.125 0.0\n",
      "boost Synset('hike.v.01') 0.0 0.0\n",
      "Not Found: progress\n",
      "57\n",
      "Not Found: warp\n",
      "58\n",
      "Not Found: was\n",
      "was Synset('be.v.01') 0.25 0.125\n",
      "swift Synset('swift.n.01') 0.0 0.0\n",
      "smooth Synset('smooth.a.01') 0.25 0.0\n",
      "starting Synset('get_down.v.07') 0.0 0.0\n",
      "company Synset('company.n.01') 0.0 0.0\n",
      "said Synset('state.v.01') 0.0 0.0\n",
      "59\n",
      "finally Synset('finally.r.01') 0.0 0.0\n",
      "introduced Synset('introduce.v.01') 0.0 0.0\n",
      "is Synset('be.v.01') 0.25 0.125\n",
      "going Synset('travel.v.01') 0.0 0.0\n",
      "60\n",
      "implementation Synset('execution.n.06') 0.0 0.0\n",
      "changing Synset('change.v.01') 0.0 0.0\n",
      "is Synset('be.v.01') 0.25 0.125\n",
      "done Synset('make.v.01') 0.0 0.0\n",
      "Not Found: good\n",
      "61\n",
      "62\n",
      "is Synset('be.v.01') 0.25 0.125\n",
      "reaching Synset('reach.v.01') 0.0 0.0\n",
      "reaching Synset('reach.v.01') 0.0 0.0\n",
      "most Synset('most.r.01') 0.0 0.0\n",
      "have Synset('have.v.01') 0.25 0.0\n",
      "become Synset('become.v.01') 0.0 0.0\n",
      "t Synset('thymine.n.01') 0.0 0.0\n",
      "afford Synset('afford.v.01') 0.0 0.0\n",
      "63\n",
      "Not Found: mess\n",
      "a Synset('angstrom.n.01') 0.0 0.0\n",
      "common Synset('common.a.01') 0.0 0.0\n",
      "is Synset('be.v.01') 0.25 0.125\n",
      "forced Synset('coerce.v.01') 0.375 0.125\n",
      "64\n",
      "soul Synset('soul.n.01') 0.0 0.0\n",
      "crushing Synset('oppress.v.01') 0.0 0.25\n",
      "Not Found: depressing\n",
      "65\n",
      "are Synset('be.v.01') 0.25 0.125\n",
      "posted Synset('post.v.01') 0.0 0.0\n",
      "66\n",
      "Not Found: most\n",
      "most Synset('most.r.01') 0.0 0.0\n",
      "significant Synset('significant.a.01') 0.375 0.0\n",
      "significant Synset('significant.a.01') 0.375 0.0\n",
      "reforms Synset('reform.n.01') 0.125 0.0\n",
      "Not Found: indian\n",
      "67\n",
      "a Synset('angstrom.n.01') 0.0 0.0\n",
      "reform Synset('reform.n.01') 0.125 0.0\n",
      "s Synset('second.n.01') 0.0 0.0\n",
      "new Synset('new.a.01') 0.375 0.0\n",
      "Not Found: perfect\n",
      "be Synset('be.v.01') 0.25 0.125\n",
      "applauded Synset('applaud.v.01') 0.0 0.0\n",
      "68\n",
      "just Synset('merely.r.01') 0.0 0.0\n",
      "unhappy Synset('unhappy.a.01') 0.0 0.75\n",
      "also Synset('besides.r.02') 0.0 0.0\n",
      "angry Synset('angry.a.01') 0.375 0.375\n",
      "69\n",
      "s Synset('second.n.01') 0.0 0.0\n",
      "high Synset('high.a.01') 0.125 0.25\n",
      "some Synset('some.a.01') 0.0 0.0\n",
      "bold Synset('bold.a.01') 0.5 0.125\n",
      "Not Found: greater\n",
      "greater Synset('greater.a.01') 0.5 0.25\n",
      "good Synset('good.a.01') 0.75 0.0\n",
      "are Synset('be.v.01') 0.25 0.125\n",
      "ready Synset('ready.a.01') 0.0 0.0\n",
      "take Synset('take.v.01') 0.0 0.0\n",
      "temporary Synset('impermanent.a.01') 0.5 0.125\n",
      "Not Found: permanent\n",
      "70\n",
      "impact Synset('impact.n.01') 0.0 0.0\n",
      "good Synset('good.a.01') 0.75 0.0\n",
      "fertilisers Synset('fertilizer.n.01') 0.0 0.0\n",
      "reduced Synset('reduce.v.01') 0.125 0.0\n",
      "71\n",
      "Not Found: boost\n",
      "Not Found: positive\n",
      "72\n",
      "now Synset('now.r.01') 0.0 0.0\n",
      "clarified Synset('clarify.v.01') 0.25 0.0\n",
      "73\n",
      "be Synset('be.v.01') 0.25 0.125\n",
      "smoother Synset('smooth.a.01') 0.25 0.0\n",
      "Not Found: expected\n",
      "go Synset('travel.v.01') 0.0 0.0\n",
      "more Synset('more.r.01') 0.0 0.0\n",
      "y2k Synset('y2k.n.01') 0.0 0.0\n",
      "hoax Synset('fraud.n.03') 0.0 0.125\n",
      "Not Found: pain\n",
      "Not Found: indian\n",
      "74\n",
      "75\n",
      "pay Synset('wage.n.01') 0.0 0.0\n",
      "extra Synset('excess.s.01') 0.0 0.5\n",
      "76\n",
      "brought Synset('bring.v.01') 0.0 0.0\n",
      "brought 0.0\n",
      "not Synset('not.r.01') 0.0 0.625\n",
      "ministry Synset('ministry.n.01') 0.0 0.0\n",
      "planned Synset('plan.v.01') 0.0 0.0\n",
      "saves Synset('salvage.v.01') 0.5 0.0\n",
      "common Synset('common.a.01') 0.0 0.0\n",
      "Not Found: current\n",
      "77\n",
      "78\n",
      "in Synset('inch.n.01') 0.0 0.0\n",
      "first Synset('first.a.01') 0.0 0.0\n",
      "Not Found: raised\n",
      "Not Found: were\n",
      "were Synset('be.v.01') 0.25 0.125\n",
      "opposing Synset('oppose.v.01') 0.0 0.0\n",
      "79\n",
      "Not Found: reduction\n",
      "80\n",
      "impact Synset('impact.n.01') 0.0 0.0\n",
      "effective Synset('effective.a.01') 0.25 0.125\n",
      "81\n",
      "82\n",
      "Not Found: tiny\n",
      "s Synset('second.n.01') 0.0 0.0\n",
      "dying Synset('die.v.01') 0.0 0.0\n",
      "dying Synset('die.v.01') 0.0 0.0\n",
      "due Synset('due.a.01') 0.0 0.0\n",
      "Not Found: abnormal\n",
      "tax Synset('tax.n.01') 0.0 0.0\n",
      "danger Synset('danger.n.01') 0.125 0.625\n",
      "83\n",
      "demonetisation Synset('demonetization.n.01') 0.0 0.5\n",
      "was Synset('be.v.01') 0.25 0.125\n",
      "a Synset('angstrom.n.01') 0.0 0.0\n",
      "disaster Synset('catastrophe.n.02') 0.0 0.375\n",
      "a Synset('angstrom.n.01') 0.0 0.0\n",
      "good Synset('good.a.01') 0.75 0.0\n",
      "84\n",
      "85\n",
      "Not Found: organized\n",
      "is Synset('be.v.01') 0.25 0.125\n",
      "poised Synset('poise.v.01') 0.0 0.125\n",
      "a Synset('angstrom.n.01') 0.0 0.0\n",
      "big Synset('large.a.01') 0.25 0.125\n",
      "86\n",
      "developers Synset('developer.n.01') 0.0 0.0\n",
      "charging Synset('charge.v.01') 0.0 0.0\n",
      "giving Synset('give.v.01') 0.0 0.125\n",
      "giving -0.125\n",
      "any Synset('any.s.01') 0.0 0.0\n",
      "benefit Synset('benefit.n.01') 0.0 0.0\n",
      "fear Synset('fear.n.01') 0.0 0.875\n",
      "fear -0.875\n",
      "Not Found: anti\n",
      "profiteering Synset('profiteer.v.01') 0.0 0.0\n",
      "profiteering 0.0\n",
      "anti Synset('anti.a.01') 0.0 0.375\n",
      "87\n",
      "taking Synset('take.v.01') 0.0 0.0\n",
      "undue Synset('undue.a.01') 0.125 0.25\n",
      "advantage Synset('advantage.n.01') 0.625 0.0\n",
      "advantage 0.625\n",
      "Not Found: were\n",
      "paying Synset('pay.v.01') 0.0 0.0\n",
      "paying 0.0\n",
      "not Synset('not.r.01') 0.0 0.625\n",
      "Not Found: profiteering\n",
      "88\n",
      "Not Found: transparency\n",
      "is Synset('be.v.01') 0.25 0.125\n",
      "cheaper Synset('cheap.a.01') 0.0 0.25\n",
      "89\n",
      "are Synset('be.v.01') 0.25 0.125\n",
      "happy Synset('happy.a.01') 0.875 0.0\n",
      "90\n",
      "have Synset('have.v.01') 0.25 0.0\n",
      "recharged Synset('recharge.v.01') 0.0 0.0\n",
      "n Synset('nitrogen.n.01') 0.0 0.0\n",
      "got Synset('get.v.01') 0.125 0.0\n",
      "fair Synset('fair.a.01') 0.625 0.0\n",
      "fair 0.625\n",
      "91\n",
      "distance Synset('distance.n.01') 0.0 0.0\n",
      "travelled Synset('travel.v.01') 0.0 0.0\n",
      "has Synset('have.v.01') 0.25 0.0\n",
      "increased Synset('increase.v.01') 0.0 0.0\n",
      "at Synset('astatine.n.01') 0.0 0.0\n",
      "least Synset('least.a.01') 0.0 0.0\n",
      "92\n",
      "any Synset('any.s.01') 0.0 0.0\n",
      "decent Synset('decent.s.01') 0.875 0.0\n",
      "r Synset('roentgen.n.01') 0.0 0.0\n",
      "paying Synset('pay.v.01') 0.0 0.0\n",
      "93\n",
      "Not Found: won\n",
      "impact Synset('impact.n.01') 0.0 0.0\n",
      "growing Synset('turn.v.07') 0.0 0.0\n",
      "94\n",
      "a Synset('angstrom.n.01') 0.0 0.0\n",
      "tough Synset('tough.a.01') 0.0 0.75\n",
      "Not Found: crack\n",
      "95\n",
      "Not Found: more\n",
      "distance Synset('distance.n.01') 0.0 0.0\n",
      "due Synset('due.a.01') 0.0 0.0\n",
      "bringing Synset('bring.v.01') 0.0 0.0\n",
      "overall Synset('overall.s.01') 0.0 0.0\n",
      "96\n",
      "impact Synset('impact.n.01') 0.0 0.0\n",
      "small Synset('small.a.01') 0.0 0.375\n",
      "Not Found: unorganised\n",
      "Not Found: wholesale\n",
      "97\n",
      "job Synset('occupation.n.01') 0.0 0.0\n",
      "work Synset('work.n.01') 0.0 0.0\n",
      "s Synset('second.n.01') 0.0 0.0\n",
      "perfect Synset('perfect.a.01') 0.625 0.125\n",
      "98\n",
      "Not Found: indian\n",
      "will Synset('volition.n.01') 0.125 0.0\n",
      "benefit Synset('profit.v.01') 0.375 0.0\n",
      "99\n",
      "it Synset('information_technology.n.01') 0.0 0.0\n",
      "Not Found: ’\n",
      "s Synset('second.n.01') 0.0 0.0\n",
      "cheaper Synset('cheap.a.01') 0.0 0.25\n",
      "air Synset('air.n.01') 0.0 0.0\n",
      "conditioned Synset('condition.v.01') 0.0 0.0\n",
      "100\n",
      "a Synset('angstrom.n.01') 0.0 0.0\n",
      "critical Synset('critical.a.01') 0.0 0.5\n",
      "critical Synset('critical.a.01') 0.0 0.5\n",
      "reform Synset('reform.n.01') 0.125 0.0\n",
      "drive Synset('drive.n.01') 0.0 0.0\n",
      "economic Synset('economic.a.01') 0.0 0.0\n",
      "economic Synset('economic.a.01') 0.0 0.0\n",
      "growth Synset('growth.n.01') 0.0 0.0\n",
      "101\n",
      "Not Found: seated\n",
      "102\n",
      "trucks Synset('truck.n.01') 0.25 0.0\n",
      "idle Synset('idle.a.01') 0.0 0.625\n",
      "Not Found: retail\n",
      "as Synset('equally.r.01') 0.0 0.125\n",
      "low Synset('low.a.01') 0.0 0.25\n",
      "103\n",
      "cent Synset('cent.n.01') 0.0 0.0\n",
      "more Synset('more.r.01') 0.0 0.0\n",
      "104\n",
      "Not Found: biggest\n",
      "reset Synset('reset.v.01') 0.0 0.0\n",
      "indian Synset('indian.a.01') 0.0 0.0\n",
      "has Synset('have.v.01') 0.25 0.0\n",
      "witnessed Synset('witness.v.01') 0.0 0.0\n",
      "Not Found: disruptive\n",
      "Not Found: chaotic\n",
      "but Synset('merely.r.01') 0.0 0.0\n",
      "was Synset('be.v.01') 0.25 0.125\n",
      "was Synset('be.v.01') 0.25 0.125\n",
      "necessary Synset('necessary.a.01') 0.625 0.0\n",
      "105\n",
      "up Synset('up.r.01') 0.0 0.0\n",
      "due Synset('due.a.01') 0.0 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n",
      "Not Found: poorest\n",
      "Not Found: burden\n",
      "tax Synset('tax.n.01') 0.0 0.0\n",
      "reforms Synset('reform.n.01') 0.125 0.0\n",
      "ragpickers Synset('ragpicker.n.01') 0.0 0.0\n",
      "hit Synset('hit.v.01') 0.0 0.0\n",
      "107\n",
      "witness Synset('witness.n.01') 0.0 0.0\n",
      "reduction Synset('decrease.n.04') 0.0 0.0\n",
      "Not Found: quicker\n",
      "Not Found: less\n",
      "108\n",
      "glass Synset('glass.n.01') 0.0 0.0\n",
      "waste Synset('waste.n.01') 0.125 0.0\n",
      "Not Found: scrap\n",
      "Not Found: adverse\n",
      "on Synset('on.a.01') 0.0 0.0\n",
      "waste Synset('waste.n.01') 0.125 0.0\n",
      "109\n",
      "Not Found: new\n",
      "have Synset('have.v.01') 0.25 0.0\n",
      "left Synset('leave.v.01') 0.0 0.0\n",
      "firms Synset('firm.n.01') 0.0 0.0\n",
      "confused Synset('confuse.v.01') 0.0 0.0\n",
      "110\n",
      "Not Found: first\n",
      "111\n",
      "still Synset('still.r.01') 0.0 0.125\n",
      "unclear Synset('ill-defined.a.01') 0.375 0.125\n",
      "112\n",
      "businesses Synset('business.n.01') 0.0 0.0\n",
      "blindsided Synset('blindside.v.01') 0.0 0.75\n",
      "by Synset('by.r.01') 0.0 0.0\n",
      "unclear Synset('ill-defined.a.01') 0.375 0.125\n",
      "113\n",
      "pay Synset('pay.v.01') 0.0 0.0\n",
      "more Synset('more.a.01') 0.0 0.0\n",
      "Not Found: illegal\n",
      "114\n",
      "Not Found: doing\n",
      "business Synset('business.n.01') 0.0 0.0\n",
      "more Synset('more.r.01') 0.0 0.0\n",
      "more Synset('more.r.01') 0.0 0.0\n",
      "complicated Synset('complicated.s.01') 0.125 0.625\n",
      "115\n",
      "Not Found: hail\n",
      "116\n",
      "worst Synset('worst.a.01') 0.25 0.75\n",
      "possible Synset('possible.a.01') 0.5 0.0\n",
      "prices Synset('monetary_value.n.01') 0.0 0.0\n",
      "increased Synset('increase.v.01') 0.0 0.0\n",
      "portions Synset('part.n.01') 0.0 0.0\n",
      "gone Synset('travel.v.01') 0.0 0.0\n",
      "is Synset('be.v.01') 0.25 0.125\n",
      "most Synset('most.r.01') 0.0 0.0\n",
      "food Synset('food.n.01') 0.0 0.0\n",
      "raw Synset('natural.s.07') 0.0 0.0\n",
      "117\n",
      "Not Found: same\n",
      "same Synset('same.a.01') 0.0 0.0\n",
      "old Synset('old.a.01') 0.375 0.0\n",
      "Not Found: common\n",
      "while Synset('while.n.01') 0.0 0.0\n",
      "providing Synset('supply.v.01') 0.0 0.0\n",
      "providing Synset('supply.v.01') 0.0 0.0\n",
      "windfall Synset('windfall.n.01') 0.0 0.0\n",
      "windfall Synset('windfall.n.01') 0.0 0.0\n",
      "gains Synset('addition.n.03') 0.0 0.0\n",
      "118\n",
      "Not Found: other\n",
      "other Synset('other.a.01') 0.0 0.625\n",
      "asian Synset('asian.a.01') 0.0 0.0\n",
      "119\n",
      "Not Found: touched\n",
      "touched Synset('touch.v.01') 0.0 0.0\n",
      "new Synset('new.a.01') 0.375 0.0\n",
      "time Synset('time.n.01') 0.0 0.0\n",
      "nifty Synset('bang-up.s.01') 0.875 0.0\n",
      "nifty Synset('bang-up.s.01') 0.875 0.0\n",
      "crossed Synset('traverse.v.01') 0.0 0.0\n",
      "happily Synset('happily.r.01') 0.5 0.25\n",
      "accepting Synset('accept.v.01') 0.125 0.0\n",
      "accepting Synset('accept.v.01') 0.125 0.0\n",
      "reforms Synset('reform.n.01') 0.125 0.0\n",
      "120\n",
      "Not Found: meeting\n",
      "Not Found: lauded\n",
      "121\n",
      "has Synset('have.v.01') 0.25 0.0\n",
      "made Synset('make.v.01') 0.0 0.0\n",
      "india Synset('india.n.01') 0.0 0.0\n",
      "more Synset('more.r.01') 0.0 0.0\n",
      "more Synset('more.r.01') 0.0 0.0\n",
      "expensive Synset('expensive.a.01') 0.5 0.0\n",
      "Not Found: exposed\n",
      "Not Found: low\n",
      "122\n",
      "such Synset('such.s.01') 0.0 0.125\n",
      "high Synset('high.a.01') 0.125 0.25\n",
      "an Synset('associate_in_nursing.n.01') 0.0 0.125\n",
      "basic Synset('basic.a.01') 0.0 0.0\n",
      "123\n",
      "remain Synset('stay.v.01') 0.0 0.0\n",
      "shut Synset('close.v.01') 0.0 0.0\n",
      "in Synset('inch.n.01') 0.0 0.0\n",
      "protest Synset('protest.n.01') 0.0 0.0\n",
      "124\n",
      "Not Found: faith\n",
      "125\n",
      "on Synset('on.a.01') 0.0 0.0\n",
      "2nd Synset('second.s.01') 0.0 0.0\n",
      "on Synset('on.a.01') 0.0 0.0\n",
      "3rd Synset('third.s.01') 0.0 0.0\n",
      "on Synset('on.a.01') 0.0 0.0\n",
      "4th Synset('fourth.s.01') 0.0 0.0\n",
      "Not Found: nuclear\n",
      "126\n",
      "be Synset('be.v.01') 0.25 0.125\n",
      "stopped Synset('stop.v.01') 0.0 0.0\n",
      "is Synset('be.v.01') 0.25 0.125\n",
      "going Synset('travel.v.01') 0.0 0.0\n",
      "on Synset('on.a.01') 0.0 0.0\n",
      "unhindered Synset('unhampered.s.01') 0.0 0.625\n",
      "t Synset('thymine.n.01') 0.0 0.0\n",
      "applicable Synset('applicable.s.01') 0.5 0.0\n",
      "127\n",
      "help Synset('aid.n.02') 0.5 0.0\n",
      "indian Synset('indian.a.01') 0.0 0.0\n",
      "128\n",
      "129\n",
      "s Synset('second.n.01') 0.0 0.0\n",
      "most Synset('most.r.01') 0.0 0.0\n",
      "most Synset('most.r.01') 0.0 0.0\n",
      "ambitious Synset('ambitious.a.01') 0.5 0.125\n",
      "ambitious Synset('ambitious.a.01') 0.5 0.125\n",
      "economic Synset('economic.a.01') 0.0 0.0\n",
      "economic Synset('economic.a.01') 0.0 0.0\n",
      "reform Synset('reform.n.01') 0.125 0.0\n",
      "Not Found: proud\n",
      "its Synset('information_technology.n.01') 0.0 0.0\n",
      "powered Synset('power.v.01') 0.0 0.0\n",
      "130\n",
      "Not Found: indian\n",
      "Not Found: supporting\n",
      "131\n",
      "Not Found: little\n",
      "demonetisation Synset('demonetization.n.01') 0.0 0.5\n",
      "Neg-Boost: [('little', 'JJ'), ('demonetisation', 'NN')] -0.875\n",
      "demonetisation Synset('demonetization.n.01') 0.0 0.5\n",
      "left Synset('leave.v.01') 0.0 0.0\n",
      "left Synset('left.r.01') 0.0 0.0\n",
      "undone Synset('undo.v.01') 0.0 0.0\n",
      "Not Found: did\n",
      "132\n",
      "on Synset('on.a.01') 0.0 0.0\n",
      "indian Synset('indian.a.01') 0.0 0.0\n",
      "Not Found: greatness\n",
      "133\n",
      "it Synset('information_technology.n.01') 0.0 0.0\n",
      "got Synset('get.v.01') 0.125 0.0\n",
      "got Synset('get.v.01') 0.125 0.0\n",
      "Not Found: aborted\n",
      "labour Synset('labor.n.01') 0.0 0.0\n",
      "pain Synset('pain.n.01') 0.0 0.75\n",
      "in Synset('inch.n.01') 0.0 0.0\n",
      "less Synset('less.a.01') 0.0 0.5\n",
      "134\n",
      "in Synset('inch.n.01') 0.0 0.0\n",
      "high Synset('high.a.01') 0.125 0.25\n",
      "why Synset('why.n.01') 0.0 0.0\n",
      "torment Synset('torment.v.01') 0.375 0.0\n",
      "135\n",
      "more Synset('more.r.01') 0.0 0.0\n",
      "more 0.0\n",
      "no Synset('no.n.01') 0.0 0.25\n",
      "Not Found: biggest\n",
      "tax Synset('tax.n.01') 0.0 0.0\n",
      "reform Synset('reform.n.01') 0.125 0.0\n",
      "136\n",
      "has Synset('have.v.01') 0.25 0.0\n",
      "transformed Synset('transform.v.01') 0.0 0.0\n",
      "137\n",
      "Not Found: monthly\n",
      "provision Synset('provision.n.01') 0.0 0.0\n",
      "got Synset('get.v.01') 0.125 0.0\n",
      "Not Found: hike\n",
      "Not Found: same\n",
      "Not Found: last\n",
      "salary Synset('wage.n.01') 0.0 0.0\n",
      "won Synset('win.v.01') 0.125 0.0\n",
      "Not Found: much\n",
      "much Synset('much.a.01') 0.0 0.0\n",
      "hike Synset('hike.n.01') 0.0 0.0\n",
      "138\n",
      "hs Synset('hassium.n.01') 0.0 0.0\n",
      "brought Synset('bring.v.01') 0.0 0.0\n",
      "is Synset('be.v.01') 0.25 0.125\n",
      "daily Synset('daily.s.01') 0.0 0.0\n",
      "Not Found: most\n",
      "shops Synset('shop.n.01') 0.0 0.0\n",
      "gone Synset('travel.v.01') 0.0 0.0\n",
      "r Synset('roentgen.n.01') 0.0 0.0\n",
      "broke Synset('interrupt.v.04') 0.25 0.125\n",
      "139\n",
      "giant Synset('elephantine.s.01') 0.375 0.0\n",
      "sanitary Synset('sanitary.a.01') 0.625 0.25\n",
      "chennai Synset('chennai.n.01') 0.0 0.0\n",
      "protest Synset('protest.n.01') 0.0 0.0\n",
      "140\n",
      "s Synset('second.n.01') 0.0 0.0\n",
      "largest Synset('large.a.01') 0.25 0.125\n",
      "is Synset('be.v.01') 0.25 0.125\n",
      "shut Synset('close.v.01') 0.0 0.0\n",
      "Not Found: strange\n",
      "has Synset('have.v.01') 0.25 0.0\n",
      "downplayed Synset('understate.v.01') 0.375 0.0\n",
      "141\n",
      "a Synset('angstrom.n.01') 0.0 0.0\n",
      "leading Synset('lead.v.01') 0.0 0.0\n",
      "s Synset('second.n.01') 0.0 0.0\n",
      "top Synset('top.a.01') 0.0 0.0\n",
      "s Synset('second.n.01') 0.0 0.0\n",
      "convinced Synset('convert.v.09') 0.125 0.0\n",
      "Not Found: multiple\n",
      "will Synset('volition.n.01') 0.125 0.0\n",
      "dent Synset('dent.n.01') 0.0 0.0\n",
      "142\n",
      "is Synset('be.v.01') 0.25 0.125\n",
      "great Synset('great.s.01') 0.0 0.0\n",
      "fertilisers Synset('fertilizer.n.01') 0.0 0.0\n",
      "reduced Synset('reduce.v.01') 0.125 0.0\n",
      "Not Found: .indian\n",
      "143\n"
     ]
    }
   ],
   "source": [
    "fw=open(\"tweets.txt\",\"r\",encoding=\"utf-8\")\n",
    "rw=open(\"normSentiwordnet_stan_tweet_result.txt\",\"a\",encoding='utf-8')\n",
    "tw=fw.read().split('\\n')\n",
    "i=0\n",
    "for t in tw:\n",
    "    i+=1\n",
    "    score=0.0\n",
    "    tok_tweet=word_tokenize(clean_tweet(t.lower()))\n",
    "    bigrams=nltk.ngrams(tok_tweet,2)\n",
    "    score=check(bigrams)\n",
    "    rw.write(str(t)+\"  :\"+str(score)+\"\\n\")\n",
    "    print(i)\n",
    "fw.close()\n",
    "rw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
