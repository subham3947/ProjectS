{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk import sent_tokenize,word_tokenize,pos_tag,FreqDist\n",
    "from collections import Counter\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_words = []\n",
    "f=open(\"C:/Users/NAKUL/Desktop/SentiWordNet_3.0.0_20130122.txt\",\"r\",encoding=\"utf-8\") \n",
    "lines=f.readlines()\n",
    "for line in lines:\n",
    "    \n",
    "    w=line.split('\\t')[4]\n",
    "    #print(w)\n",
    "    i=w.index('#')\n",
    "    #print(i)\n",
    "    senti_words.append(w[:i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "senti_words.index('')+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"C:/Users/NAKUL/Desktop/01-07-2017_all_article.txt\", \"r\",encoding=\"utf8\")\n",
    "s=f.read()\n",
    "words=word_tokenize(s.lower())\n",
    "lex_words=set()\n",
    "for w in words:\n",
    "    if w in senti_words:\n",
    "        lex_words.add(w)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_tag(tag):\n",
    "    \n",
    "    if tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    elif tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#find frequency distribution\n",
    "Freqdist=dict(Counter(words))\n",
    "#print(Freqdist)\n",
    "freq_set=set()\n",
    "for w in Freqdist:\n",
    "    freq_set.add(Freqdist[w])\n",
    "freq_set=sorted(freq_set,reverse=True)\n",
    "freq_set=list(freq_set)\n",
    "#print(freq_set)\n",
    "#find rank\n",
    "rank={}  \n",
    "for k,v in Freqdist.items():\n",
    "    rank[k]=freq_set.index(v)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rank['triumph']\n",
    "Freqdist['triumph']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "tagged_words=pos_tag(list(lex_words))\n",
    "wfile = open(\"samplelexicon.txt\",\"a\",encoding='utf-8')\n",
    "for word, tag in tagged_words:\n",
    "        rf=rank[word]*Freqdist[word]\n",
    "        wn_tag = convert_tag(tag)\n",
    "        if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV,wn.VERB):\n",
    "            continue\n",
    "    \n",
    "        synsets = wn.synsets(word)\n",
    "        if not synsets:\n",
    "            continue\n",
    "        synonyms=''\n",
    "        for s in synsets:\n",
    "            synonyms+='#'+s.lemmas()[0].name()\n",
    "            # Take the first sense, the most common\n",
    "        synset = synsets[0]\n",
    "        swn_synset = swn.senti_synset(synset.name())\n",
    "        modified_pos_score=(1/(rf))+swn_synset.pos_score() \n",
    "        modified_neg_score=(1/(rf))+swn_synset.neg_score()\n",
    "        wfile.write(wn_tag+'\\t'+word+'\\t'+str(modified_pos_score)+'\\t'+str(modified_neg_score)+'\\t'+synonyms+'\\n')\n",
    "print('write complete')\n",
    "wfile.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write complete\n"
     ]
    }
   ],
   "source": [
    "tagged_words=pos_tag(list(lex_words))\n",
    "wfile = open(\"improvedsamplelexicon.txt\",\"a\",encoding='utf-8')\n",
    "for word, tag in tagged_words:\n",
    "        rf=rank[word]*Freqdist[word]\n",
    "        wn_tag = convert_tag(tag)\n",
    "        if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV,wn.VERB):\n",
    "            continue\n",
    "        #finding synonyms\n",
    "        synsets = wn.synsets(word)\n",
    "        synonyms=''\n",
    "        for s in synsets:\n",
    "            synonyms+='#'+s.lemmas()[0].name()\n",
    "            \n",
    "        #find lemma for the word\n",
    "        lemma=lemmatizer.lemmatize('word',wn_tag)\n",
    "        #if word in sentiwordnet\n",
    "        if word in senti_words:\n",
    "            line_no=lines[senti_words.index(word)]\n",
    "            pos_score,neg_score=line_no.split('\\t')[2],line_no.split('\\t')[3]\n",
    "        #or else if lemma in sentiwordnet\n",
    "        elif lemma in senti_words: \n",
    "            line_no=lines[senti_words.index(lemma)]\n",
    "            pos_score,neg_score=line_no.split('\\t')[2],line_no.split('\\t')[3]\n",
    "        #if not then skip\n",
    "        else:\n",
    "            continue\n",
    "        modified_pos_score=(1/(rf))+float(pos_score) \n",
    "        modified_neg_score=(1/(rf))+float(neg_score)\n",
    "        wfile.write(wn_tag+'\\t'+word+'\\t'+str(modified_pos_score)+'\\t'+str(modified_neg_score)+'\\t'+synonyms+'\\n')\n",
    "print('write complete')\n",
    "wfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#neutral words\n",
    "file = open(\"samplelexicon.txt\",\"r\",encoding='utf-8')\n",
    "i=0\n",
    "for line in file:\n",
    "        pos,neg=line.split('\\t')[2],line.split('\\t')[3]\n",
    "        if pos==neg :\n",
    "            i+=1\n",
    "            print(i,line.split('\\t')[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
