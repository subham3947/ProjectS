{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\nltk\\tag\\stanford.py:149: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordPOSTagger, self).__init__(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "from nltk import word_tokenize,sent_tokenize,pos_tag\n",
    "from nltk.tag import StanfordPOSTagger\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "java_path = \"C:/Program Files/Java/jdk1.8.0_144/bin/java.exe\"\n",
    "os.environ['JAVAHOME'] = java_path\n",
    "model='stanford-postagger-2018-02-27/models/english-left3words-distsim.tagger'\n",
    "jar='stanford-postagger-2018-02-27/stanford-postagger-3.9.1.jar'\n",
    "st=StanfordPOSTagger(model,jar,encoding='utf-8')\n",
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_words = []\n",
    "f=open(\"D:/Lex/SentiWordNet_3.0.0_20130122.txt\",\"r\",encoding=\"utf-8\") \n",
    "all_lines=f.readlines()\n",
    "for line in all_lines:\n",
    "    \n",
    "    w=line.split('\\t')[4]\n",
    "    #print(w)\n",
    "    i=w.index('#')\n",
    "    #print(i)\n",
    "    senti_words.append(w[:i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_words = []\n",
    "f=open(\"improvedsamplelexicon.txt\",\"r\",encoding=\"utf-8\") \n",
    "all_lines=f.readlines()\n",
    "for line in all_lines:\n",
    "    \n",
    "    w=line.split('\\t')[1]\n",
    "    senti_words.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3794"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senti_words.index('hoax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg= {\"aint\", \"arent\", \"cannot\", \"cant\", \"couldnt\", \"darent\", \"didnt\", \"doesnt\",\n",
    " \"ain't\", \"aren't\", \"can't\", \"couldn't\", \"daren't\", \"didn't\", \"doesn't\",\n",
    " \"dont\", \"hadnt\", \"hasnt\", \"havent\", \"isnt\", \"mightnt\", \"mustnt\", \"neither\",\n",
    " \"don't\", \"hadn't\", \"hasn't\", \"haven't\", \"isn't\", \"mightn't\", \"mustn't\",\n",
    " \"neednt\", \"needn't\", \"never\",\"no\" \"none\", \"nope\", \"nor\", \"not\", \"nothing\", \"nowhere\",\n",
    " \"oughtnt\", \"shant\", \"shouldnt\", \"uhuh\", \"wasnt\", \"werent\",\n",
    " \"oughtn't\", \"shan't\", \"shouldn't\", \"uh-uh\", \"wasn't\", \"weren't\",\n",
    " \"without\", \"wont\", \"wouldnt\", \"won't\", \"wouldn't\", \"rarely\", \"seldom\", \"despite\",\"unfulfilled\",\"undue\",\"anti\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost={\"absolutely\":0.5, \"amazingly\":0.125, \"awfully\":0.25, \"completely\":0.25, \"considerably\":0.125,\n",
    " \"decidedly\":0.25 , \"deeply\":0.25 , \"enormously\":0.25 ,\n",
    " \"entirely\":0.5 , \"especially\":0.25 , \"exceptionally\":0.25, \"extremely\":0.625 ,\"fabulously\":0.25   , \"fully\":0.375  ,\n",
    " \"greatly\":0.125 , \"highly\":0.5   ,\"huge\":0.25, \"hugely\":0.25   , \"incredibly\":0.25   ,\n",
    " \"intensely\":0.25   , \"majorly\":0.625  ,\"particularly\":0.125 ,\"really\":0.375 ,\"substantially\":0.125   ,\n",
    " \"thoroughly\":0.625   , \"totally\":0.5  ,\"unbelievably\":0.25   , \"utterly\":0.5   ,\n",
    " \"very\":0.25  ,\"tremendously\":-0.25 ,  \"barely\":-0.375   ,\"badly\":-0.125 ,\"hardly\":-0.25,\"unusually\":-0.5   , \n",
    " \"less\":-0.5   , \"little\":-0.375   , \"marginally\":-0.125   , \"partly\":-0.125   ,\n",
    " \"scarcely\":-0.25   , \"slightly\":-0.25   , \"somewhat\":-0.125, \"shoddy\":-0.625, \"poorly\":-0.75}\n",
    "pos_boost=[\"absolutely\", \"amazingly\", \"awfully\", \"completely\", \"considerably\",\n",
    " \"decidedly\",\"deeply\",\"enormously\",\"entirely\",\"especially\",\"exceptionally\",\"extremely\",\"fabulously\",\"fully\",\n",
    " \"greatly\",\"highly\",\"huge\",\"hugely\", \"incredibly\",\"intensely\",\"majorly\",\"particularly\",\"really\",\"substantially\",\"thoroughly\",\"totally\",\"unbelievably\", \"utterly\",\"very\"]\n",
    "neg_boost=[\"tremendously\", \"barely\",\"badly\",\"hardly\",\"unusually\", \"less\", \"little\", \"marginally\", \"partly\",\n",
    " \"scarcely\", \"slightly\",\"somewhat\", \"shoddy\", \"poorly\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tag(tag):\n",
    "    \n",
    "    if tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    elif tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sentiment(word,pos):\n",
    "    found=0\n",
    "    line_nos=[index for index, value in enumerate(senti_words) if value == word]\n",
    "    lines=[all_lines[lno] for lno in line_nos]\n",
    "    if len(lines)==0:\n",
    "        return None\n",
    "    for l in lines:\n",
    "        if l[0]==pos:\n",
    "            pos_score,neg_score=l.split('\\t')[2],l.split('\\t')[3]\n",
    "            found=1\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "    if found==1:\n",
    "        return(float(pos_score)-float(neg_score))\n",
    "    else:\n",
    "        pos_score,neg_score=lines[0].split('\\t')[2],lines[0].split('\\t')[3]\n",
    "        return(float(pos_score)-float(neg_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(word,pos):\n",
    "    second_sent=find_sentiment(word,pos)\n",
    "            \n",
    "    if second_sent is None:\n",
    "        try:\n",
    "            lemma=lemmatizer.lemmatize(word,pos)\n",
    "            synsets = wn.synsets(lemma)\n",
    "            synset=synsets[0]\n",
    "            s=synset.name()\n",
    "            i=s.index('.')\n",
    "            second_sent=find_sentiment(s[:i],pos)\n",
    "            #print(s[:i],second_sent)\n",
    "            if second_sent is None:\n",
    "                second_sent=0.0\n",
    "        except:\n",
    "            second_sent=0.0\n",
    "    return second_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(score):\n",
    "    return((score-(-1.875))/3.125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns=open('sent_nouns.txt','r',encoding='utf-8')\n",
    "nouns=nouns.read()\n",
    "nouns=nouns.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = '''!@'#-+='''\n",
    "def clean_tweet(t):\n",
    "    for c in punctuations:\n",
    "             t= t.replace(c,\"\")\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_booster(booster,word,pos2):\n",
    "    sec_score=get_sentiment(word,pos2)\n",
    "    if sec_score>0.0:\n",
    "        return(boost[booster]+sec_score)\n",
    "    if sec_score<0.0:\n",
    "        return(sec_score-boost[booster])\n",
    "    else:\n",
    "        return(boost[booster])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_booster(booster,word,pos2):\n",
    "    sec_score=get_sentiment(word,pos2)\n",
    "    if sec_score>0.0:\n",
    "        return(sec_score+boost[booster])\n",
    "    if sec_score<0.0:\n",
    "        return(sec_score+boost[booster])\n",
    "    else:\n",
    "        return(boost[booster])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet1='''The marginalization of the Tax Cheats which was expected post #GST will now happen in right earnest as #Ewaybill rolls out. Real benefits to most organized sector companies will be seen in FY2019'''\n",
    "tweet2='''From Failed #Demonetisation to Shoddy Implementation of #GST to poorly performing #Economy to unfulfilled Promise of reduction in fuel prices to not keeping the promises of providing 2 crores jobs, BJP has wrecked a nation & has broken peopleâ€™s faith '''\n",
    "tweet3='''There is nothing wrong with #GST implementation but the fact is we are all losers. Injected to us by @INCIndia  Even God cannot change'''\n",
    "tweet4='''So, Indian businesses are mad against GST cause now they have to pay tax and earlier they weren't?'''\n",
    "tweet5='''#GST in india is total failure,it like nightmare for tax payers Indians..in my view it could be rolled out after #2019LSPolls after corrections ~ Dr Subramanian @Swamy39 Speaking at 14th Annual ðŸ‡®ðŸ‡³India Business Conference on â€˜Indian Growth @Columbia_Biz '''\n",
    "tweet6='''#GST complexities and high tax slabs is really killing small-businesses in India. It only aims at ultimately benefitting the big businessmen.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=word_tokenize(clean_tweet(tweet6.lower()))\n",
    "bigrams=nltk.ngrams(A,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('gst', 'NN'), ('complexities', 'NNS')]\n",
      "complexity None\n",
      "Normal: [('gst', 'NN'), ('complexities', 'NNS')] 0.0\n",
      "[('complexities', 'NNS'), ('and', 'CC')]\n",
      "[('and', 'CC'), ('high', 'JJ')]\n",
      "Normal: [('and', 'CC'), ('high', 'JJ')] 0.125\n",
      "[('high', 'JJ'), ('tax', 'NN')]\n",
      "[('tax', 'NN'), ('slabs', 'NNS')]\n",
      "[('slabs', 'NNS'), ('is', 'VBZ')]\n",
      "[('is', 'VBZ'), ('really', 'RB')]\n",
      "[('really', 'RB'), ('killing', 'VBG')]\n",
      "Pos-Boost: [('really', 'RB'), ('killing', 'VBG')] -0.625\n",
      "[('killing', 'VBG'), ('smallbusinesses', 'NNS')]\n",
      "[('smallbusinesses', 'NNS'), ('in', 'IN')]\n",
      "[('in', 'IN'), ('india', 'NN')]\n",
      "[('india', 'NN'), ('.', '.')]\n",
      "[('.', '.'), ('it', 'PRP')]\n",
      "[('it', 'PRP'), ('only', 'RB')]\n",
      "[('only', 'RB'), ('aims', 'VBZ')]\n",
      "[('aims', 'NNS'), ('at', 'IN')]\n",
      "[('at', 'IN'), ('ultimately', 'RB')]\n",
      "[('ultimately', 'RB'), ('benefitting', 'VBG')]\n",
      "benefit 0.375\n",
      "Normal: [('ultimately', 'RB'), ('benefitting', 'VBG')] -0.25\n",
      "[('benefitting', 'VBG'), ('the', 'DT')]\n",
      "[('the', 'DT'), ('big', 'JJ')]\n",
      "Normal: [('the', 'DT'), ('big', 'JJ')] 0.25\n",
      "[('big', 'JJ'), ('businessmen', 'NNS')]\n",
      "[('businessmen', 'NNS'), ('.', '.')]\n",
      "0.68\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "not_found=set()\n",
    "score=0.0\n",
    "for b in bigrams:\n",
    "    i+=1\n",
    "    b_tag=st.tag(b)\n",
    "    print(b_tag)\n",
    "    second_gram=b_tag[1]\n",
    "    first_gram=b_tag[0]\n",
    "    if second_gram[0] in nouns or second_gram[1].startswith('J') or second_gram[1].startswith('RBR') or second_gram[1].startswith('RBS') or second_gram[1].startswith('VBG') or second_gram[1].startswith('VBN') or second_gram[1].startswith('VBD'):\n",
    "    #if second_gram[0] in nouns or second_gram[1].startswith('J') or second_gram[1].startswith('RBR') or second_gram[1].startswith('RBS') or second_gram[1].startswith('VB'):\n",
    "        pos2=convert_tag(second_gram[1])\n",
    "        pos1=convert_tag(first_gram[1])\n",
    "        \n",
    "        if first_gram[0] in boost:\n",
    "            if first_gram[0] in pos_boost:\n",
    "                score=positive_booster(first_gram[0],second_gram[0],pos2)\n",
    "                print('Pos-Boost:',b_tag,score)\n",
    "            if first_gram[0] in neg_boost:\n",
    "                score=negative_booster(first_gram[0],second_gram[0],pos2)\n",
    "                print('Neg-Boost:',b_tag,score)\n",
    "            \n",
    "   \n",
    "        if first_gram[0] in neg:\n",
    "                sec_score=get_sentiment(second_gram[0],pos2)\n",
    "                print(second_gram[0],sec_score)\n",
    "                if sec_score ==0.0 or sec_score==None:\n",
    "                    score+=(get_sentiment(first_gram[0],pos1)+sec_score)\n",
    "                else:\n",
    "                    score+=-(sec_score)\n",
    "                print('Neg:',b_tag,score)\n",
    "            \n",
    "        elif first_gram[0] not in neg and first_gram[0] not in boost:\n",
    "            try:\n",
    "                first_score=get_sentiment(first_gram[0],pos1)\n",
    "                score+=first_score+get_sentiment(second_gram[0],pos2)\n",
    "                print('Normal:',b_tag,score)\n",
    "            except:\n",
    "                print(\"Not Found:\",second_gram[0])\n",
    "                not_found.add(second_gram[0])\n",
    "    \n",
    "print(normalize(score))\n",
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(bigrams):\n",
    "    score=0.0\n",
    "    for b in bigrams:\n",
    "        #b_tag=st.tag(b)\n",
    "        b_tag=pos_tag(b)\n",
    "        #print(b_tag)\n",
    "        second_gram=b_tag[1]\n",
    "        first_gram=b_tag[0]\n",
    "        if second_gram[0] in nouns or second_gram[1].startswith('J') or second_gram[1].startswith('RBR') or second_gram[1].startswith('RBS') or second_gram[1].startswith('VBG') or second_gram[1].startswith('VBN') or second_gram[1].startswith('VBD'):\n",
    "            pos2=convert_tag(second_gram[1])\n",
    "            pos1=convert_tag(first_gram[1])\n",
    "        \n",
    "            if first_gram[0] in boost:\n",
    "                if first_gram[0] in pos_boost:\n",
    "                    score=positive_booster(first_gram[0],second_gram[0],pos2)\n",
    "                    print('Pos-Boost:',b_tag,score)\n",
    "                if first_gram[0] in neg_boost:\n",
    "                    score=negative_booster(first_gram[0],second_gram[0],pos2)\n",
    "                    print('Neg-Boost:',b_tag,score)\n",
    "            \n",
    "   \n",
    "            if first_gram[0] in neg:\n",
    "                x=0.0\n",
    "                sec_score=get_sentiment(second_gram[0],pos2)\n",
    "                print(second_gram[0],sec_score)\n",
    "                if sec_score ==0.0 or sec_score==None:\n",
    "                    try:\n",
    "                        x=get_sentiment(first_gram[0],pos1)\n",
    "                        score+=(x+sec_score)\n",
    "                    except:\n",
    "                        print(x)\n",
    "                else:\n",
    "                    score+=-(sec_score)\n",
    "                print('Neg:',b_tag,score)\n",
    "            \n",
    "            elif first_gram[0] not in neg and first_gram[0] not in boost:\n",
    "                try:\n",
    "                    first_score=get_sentiment(first_gram[0],pos1)\n",
    "                    score+=first_score+get_sentiment(second_gram[0],pos2)\n",
    "                    print('Normal:',b_tag,score)\n",
    "                except:\n",
    "                    print(\"Not Found:\",second_gram[0])\n",
    "                    #not_found.add(second_gram[0])\n",
    "    return (score)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "1\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "2\n",
      "3\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "4\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "5\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "6\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "7\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "8\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "9\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "10\n",
      "<class 'float'>\n",
      "11\n",
      "<class 'float'>\n",
      "Neg-Boost: [('badly', 'RB'), ('affected', 'VBD')] -0.625\n",
      "<class 'float'>\n",
      "12\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "13\n",
      "<class 'float'>\n",
      "14\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "15\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "16\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "17\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "18\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "19\n",
      "<class 'float'>\n",
      "20\n",
      "<class 'float'>\n",
      "21\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "22\n",
      "afford 0.0\n",
      "Neg: [('not', 'RB'), ('afford', 'VB')] -0.625\n",
      "<class 'float'>\n",
      "23\n",
      "Pos-Boost: [('very', 'RB'), ('good', 'JJ')] 0.875\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "24\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "25\n",
      "<class 'float'>\n",
      "26\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "27\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "28\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "29\n",
      "30\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "31\n",
      "32\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "33\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "34\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "35\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "36\n",
      "<class 'float'>\n",
      "37\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "38\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "39\n",
      "40\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "41\n",
      "<class 'float'>\n",
      "42\n",
      "<class 'float'>\n",
      "43\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "44\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "45\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "46\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "47\n",
      "<class 'float'>\n",
      "48\n",
      "going 0.0\n",
      "Neg: [('not', 'RB'), ('going', 'VBG')] -0.625\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "49\n",
      "50\n",
      "<class 'float'>\n",
      "Pos-Boost: [('completely', 'RB'), ('stopped', 'VBD')] 0.25\n",
      "51\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "52\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "53\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "54\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "55\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "56\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "57\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "58\n",
      "<class 'float'>\n",
      "59\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "60\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "61\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "62\n",
      "63\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "afford 0.0\n",
      "Neg: [('cant', 'NN'), ('afford', 'NN')] 0.0\n",
      "64\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "65\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "66\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "67\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "68\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "69\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "70\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "71\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "72\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "73\n",
      "<class 'float'>\n",
      "74\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "75\n",
      "76\n",
      "77\n",
      "brought 0.0\n",
      "Neg: [('not', 'RB'), ('brought', 'VBN')] -0.625\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "78\n",
      "79\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "80\n",
      "<class 'float'>\n",
      "81\n",
      "<class 'float'>\n",
      "82\n",
      "83\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "84\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "85\n",
      "86\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "87\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "giving 0.0\n",
      "Neg: [('without', 'IN'), ('giving', 'VBG')] 0.0\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "profiteering 0.0\n",
      "Neg: [('anti', 'NNS'), ('profiteering', 'VBG')] -0.625\n",
      "88\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "advantage 0.625\n",
      "Neg: [('undue', 'JJ'), ('advantage', 'NN')] -0.75\n",
      "<class 'float'>\n",
      "paying 0.0\n",
      "Neg: [('not', 'RB'), ('paying', 'VBG')] -1.375\n",
      "89\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "90\n",
      "<class 'float'>\n",
      "91\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "fair 0.375\n",
      "Neg: [('not', 'RB'), ('fair', 'JJ')] -0.375\n",
      "92\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "93\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "94\n",
      "<class 'float'>\n",
      "95\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "96\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "97\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "98\n",
      "<class 'float'>\n",
      "99\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "100\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "101\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "102\n",
      "<class 'float'>\n",
      "103\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "104\n",
      "<class 'float'>\n",
      "105\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "106\n",
      "<class 'float'>\n",
      "107\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "108\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "109\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "110\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "111\n",
      "<class 'float'>\n",
      "112\n",
      "<class 'float'>\n",
      "113\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "114\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "115\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "116\n",
      "<class 'float'>\n",
      "117\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "118\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "119\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "120\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "121\n",
      "<class 'float'>\n",
      "122\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "123\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "124\n",
      "<class 'float'>\n",
      "125\n",
      "<class 'float'>\n",
      "126\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "127\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "applicable 0.5\n",
      "Neg: [('isnt', 'NN'), ('applicable', 'JJ')] -1.125\n",
      "128\n",
      "129\n",
      "130\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "131\n",
      "<class 'float'>\n",
      "132\n",
      "<class 'float'>\n",
      "Neg-Boost: [('little', 'JJ'), ('demonetisation', 'NN')] -0.875\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "133\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "134\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "135\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "136\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "137\n",
      "<class 'float'>\n",
      "138\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "139\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "140\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "141\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "142\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "143\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "144\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "145\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "146\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "147\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "148\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "149\n",
      "<class 'float'>\n",
      "150\n",
      "<class 'float'>\n",
      "151\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "152\n",
      "<class 'float'>\n",
      "153\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "154\n",
      "Pos-Boost: [('huge', 'JJ'), ('discomfort', 'NN')] -0.375\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "155\n",
      "<class 'float'>\n",
      "156\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "157\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "158\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "159\n",
      "<class 'float'>\n",
      "160\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "161\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "162\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "163\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "164\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "165\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "166\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "169\n",
      "170\n",
      "<class 'float'>\n",
      "171\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "172\n",
      "173\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "174\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "175\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "176\n",
      "177\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "178\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "179\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "180\n",
      "181\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "182\n",
      "<class 'float'>\n",
      "183\n",
      "<class 'float'>\n",
      "Neg-Boost: [('little', 'JJ'), ('hard', 'JJ')] -1.125\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "184\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "185\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "186\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "187\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "188\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "189\n",
      "<class 'float'>\n",
      "190\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "191\n",
      "<class 'float'>\n",
      "192\n"
     ]
    }
   ],
   "source": [
    "fw=open(\"tweets.txt\",\"r\",encoding=\"utf-8\")\n",
    "rw=open(\"nltk_tweet_result.txt\",\"a\",encoding='utf-8')\n",
    "tw=fw.read().split('\\n')\n",
    "i=0\n",
    "for t in tw:\n",
    "    i+=1\n",
    "    score=0.0\n",
    "    tok_tweet=word_tokenize(clean_tweet(t.lower()))\n",
    "    bigrams=nltk.ngrams(tok_tweet,2)\n",
    "    score=check(bigrams)\n",
    "    rw.write(str(t)+\"  :\"+str(score)+\"\\n\")\n",
    "    print(i)\n",
    "fw.close()\n",
    "rw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo=open(\"stan_tweet_result.txt\",\"r\",encoding='utf-8')\n",
    "lines=fo.readlines()\n",
    "s_list=[]\n",
    "for l in lines:\n",
    "    s_list.append(float(l.split(':')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list,neg_list=[],[]\n",
    "for s in s_list:\n",
    "    if s >=0.0:\n",
    "        pos_list.append(s)\n",
    "    if s<0.0:\n",
    "        neg_list.append(-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.06727784728718064,\n",
       " 0.625,\n",
       " 1.25,\n",
       " 0.378,\n",
       " 0.5,\n",
       " 0.125,\n",
       " 0.25,\n",
       " 0.625,\n",
       " 0.5,\n",
       " 1.375,\n",
       " 0.625,\n",
       " 0.03582397526189089,\n",
       " 0.25,\n",
       " 0.125,\n",
       " 0.125,\n",
       " 0.75,\n",
       " 0.5,\n",
       " 1.375,\n",
       " 0.03582397526189089,\n",
       " 0.25,\n",
       " 1.381,\n",
       " 0.125,\n",
       " 0.25,\n",
       " 0.25,\n",
       " 0.75,\n",
       " 1.25,\n",
       " 0.875,\n",
       " 0.06727784728718064,\n",
       " 0.625,\n",
       " 1.125,\n",
       " 0.625,\n",
       " 1.375,\n",
       " 0.375,\n",
       " 1.375,\n",
       " 0.75,\n",
       " 1.5,\n",
       " 0.5,\n",
       " 0.75,\n",
       " 0.375,\n",
       " 0.375,\n",
       " 0.375,\n",
       " 0.375,\n",
       " 0.5,\n",
       " 0.875,\n",
       " 0.378,\n",
       " 1.125,\n",
       " 1.125,\n",
       " 1.875,\n",
       " 0.5,\n",
       " 0.03582397526189089,\n",
       " 0.625,\n",
       " 0.25,\n",
       " 0.125,\n",
       " 0.375,\n",
       " 0.25,\n",
       " 1.375,\n",
       " 0.125,\n",
       " 0.25,\n",
       " 0.03582397526189089,\n",
       " 1.0,\n",
       " 0.0358239752618908,\n",
       " 0.375,\n",
       " 0.03582397526189089,\n",
       " 0.125,\n",
       " 0.625,\n",
       " 0.125,\n",
       " 0.125,\n",
       " 0.25,\n",
       " 0.625,\n",
       " 0.5,\n",
       " 0.25]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(neg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "word='loot'\n",
    "lemma = lemmatizer.lemmatize(word)            \n",
    "synsets = wn.synsets(lemma)\n",
    "synset = synsets[0]\n",
    "swn_synset = swn.senti_synset(synset.name())\n",
    "print(swn_synset.pos_score()) \n",
    "print(swn_synset.neg_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loot'"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loot'"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=synset.name()\n",
    "i=s.index('.')\n",
    "s[:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "if word in senti_words:\n",
    "    line_nos=[index+1 for index, value in enumerate(senti_words) if value == word]\n",
    "    line_no=all_lines[senti_words.index(word)]\n",
    "    pos_score,neg_score=line_no.split('\\t')[2],line_no.split('\\t')[3]\n",
    "            \n",
    "\n",
    "elif lemma in senti_words: \n",
    "    line_no=lines[senti_words.index(lemma)]\n",
    "    pos_score,neg_score=line_no.split('\\t')[2],line_no.split('\\t')[3]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14272]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[index+1 for index, value in enumerate(senti_words) if value == 'mad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a\\t02572038\\t0.375\\t0.25\\tmad#4 insane#2 harebrained#1\\tvery foolish; \"harebrained ideas\"; \"took insane risks behind the wheel\"; \"a completely mad scheme to build a bridge between two mountains\"\\n'"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('demonetization', 'NN'),\n",
       " ('+', 'NNP'),\n",
       " ('gst', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('biggest', 'JJS'),\n",
       " ('reset', 'NN'),\n",
       " ('indian', 'JJ'),\n",
       " ('economy', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('witnessed', 'VBN'),\n",
       " ('since', 'IN'),\n",
       " ('1991.', 'CD'),\n",
       " ('yes', 'NNS'),\n",
       " ('...', ':'),\n",
       " ('disruptive', 'NN'),\n",
       " (',', ','),\n",
       " ('chaotic', 'JJ'),\n",
       " ('but', 'CC'),\n",
       " ('was', 'VBD'),\n",
       " ('necessary', 'JJ')]"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a='''Demonetization + GST is the biggest reset Indian Economy has witnessed since 1991. Yes...disruptive, chaotic but was necessary '''\n",
    "a=word_tokenize(a.lower())\n",
    "\n",
    "pos_tag(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
